{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Импорты"
      ],
      "metadata": {
        "id": "MAvRb_xH_cNt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5hPmSr2-I6W"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import re\n",
        "import csv\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ry2KnJ_A8v9",
        "outputId": "ac0acdd3-b767-4e94-a90a-7b0c7b839f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Константы"
      ],
      "metadata": {
        "id": "7FwXAlf3Bgfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CURR_DIR = '/content/drive/MyDrive/lab2_ntrps'"
      ],
      "metadata": {
        "id": "oJ8Fzb6IBiIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции"
      ],
      "metadata": {
        "id": "wpGoQwYF_khT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверка наличия репозиториев датасета"
      ],
      "metadata": {
        "id": "ZssMDW5r_mKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_dataset(name: str) -> None:\n",
        "    dataset_directory = os.path.join(CURR_DIR, name)\n",
        "    if not os.path.exists(dataset_directory):\n",
        "        os.makedirs(dataset_directory)\n",
        "\n",
        "def check_repo_dataset(class_name: str, folder: str) -> str:\n",
        "    class_folder = os.path.join(CURR_DIR + f'/dataset/{folder}', class_name)\n",
        "    if not os.path.exists(class_folder):\n",
        "        os.makedirs(class_folder)\n",
        "        return class_folder\n",
        "    else:\n",
        "        return class_folder"
      ],
      "metadata": {
        "id": "GCJyL5HSB4Np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Парсер ссылки на картинку"
      ],
      "metadata": {
        "id": "UZuxYTT3CbNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parser_url(url: str) -> str:\n",
        "    pattern = r'img_url=([^&]+)&text='\n",
        "    match = re.search(pattern, url)\n",
        "\n",
        "    if match:\n",
        "        img_url_encoded = match.group(1)\n",
        "        img_url_decoded = img_url_encoded.replace('%2F', '/').replace('%3A', ':')\n",
        "        return img_url_decoded\n",
        "    else:\n",
        "        print('Ссылка после img_url не найдена в URL')"
      ],
      "metadata": {
        "id": "ZSLgfEpqCcF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вычисления необходимого количества страниц для скачивания (1 страница = 30 картинкам)"
      ],
      "metadata": {
        "id": "nFyDChj4CdLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_pages(num_images: int) -> int:\n",
        "    return num_images // 30 + (num_images % 30 > 0) if num_images > 30 else 1"
      ],
      "metadata": {
        "id": "TpD2k1kaCeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Получение HTML тегов"
      ],
      "metadata": {
        "id": "LMxodLbICfLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_html_tags(mini_images: bool) -> tuple[str, str, str]:\n",
        "    if mini_images:\n",
        "        return 'img', 'serp-item__thumb', 'src'\n",
        "    else:\n",
        "        return 'a', 'serp-item__link', 'href'"
      ],
      "metadata": {
        "id": "ZbJcpvz_Cgcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запись в CSV"
      ],
      "metadata": {
        "id": "uL_fsAesYq8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv_file(path: str, data: list) -> None:\n",
        "    mode = 'w' if not os.path.exists(path) else 'a'\n",
        "    with open(path, mode, newline='') as csv_file:\n",
        "      csv_writer = csv.writer(csv_file)\n",
        "      csv_writer.writerow(data)"
      ],
      "metadata": {
        "id": "RTDNReIZYsKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Закачка картинок"
      ],
      "metadata": {
        "id": "apMvV1tFChlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image(url: str, save_path: str) -> bool:\n",
        "    try:\n",
        "        response = requests.get(url, headers={'User-Agent':'Mozilla/5.0'}, stream=True)\n",
        "        if(response.status_code == 200):\n",
        "            with open(save_path, 'wb') as file:\n",
        "                for chunk in response.iter_content(1024):\n",
        "                    file.write(chunk)\n",
        "            return True\n",
        "        else:\n",
        "            print(f'Не удалось загрузить изображение: {url}')\n",
        "            return False\n",
        "    except Exception as e:\n",
        "        print(f'Ошибка при загрузке изображения: {url}')\n",
        "        return False"
      ],
      "metadata": {
        "id": "0th9304rCiyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_images(query: str, num_images: int, mini_images: bool = False):\n",
        "    pages = calc_pages(num_images)\n",
        "    class_folder = check_repo_dataset(query, 'images')\n",
        "\n",
        "    downloaded_count = 0\n",
        "\n",
        "    base_url = 'https:'\n",
        "\n",
        "    csv_folder = check_dataset(query, 'datatset/csv')\n",
        "    csv_file_path = csv_folder + '_dataset.csv'\n",
        "\n",
        "    #а вот это чтобы без движков было, грузим странички\n",
        "    for page in range(0, pages):\n",
        "        search_url = f'https://yandex.ru/images/search?text={query}&p={page}'\n",
        "\n",
        "        write_csv_file(csv_file_path, ['date', 'file_name', 'url'])\n",
        "\n",
        "        #сделал с with для автоматического закрытия соединения\n",
        "        with requests.get(search_url, headers={'User-Agent':'Mozilla/5.0'}) as response:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "            tag, tag_class, tag_source = get_html_tags(mini_images)\n",
        "\n",
        "            for a in soup.find_all(tag, class_=tag_class):\n",
        "                img_url = a[tag_source]\n",
        "                # получаем полный URL изображения\n",
        "                if mini_images and not img_url.startswith('http'):\n",
        "                    img_url = base_url + img_url\n",
        "                elif img_url.startswith('/images'):\n",
        "                    img_url = parser_url(img_url)\n",
        "\n",
        "                #csv_image_filename = image_filename\n",
        "                image_filename = f'{downloaded_count:04d}.jpg'\n",
        "                image_path = os.path.join(class_folder, image_filename)\n",
        "                if(download_image(img_url, image_path)):\n",
        "                    downloaded_count += 1\n",
        "                    print(f\"Загружено изображений для {query}: {downloaded_count}/{num_images}\")\n",
        "\n",
        "                    write_csv_file(csv_file_path, [datetime.now().strftime('%Y-%m-%d'), image_filename, img_url])\n",
        "\n",
        "                if(downloaded_count >= num_images):\n",
        "                    break"
      ],
      "metadata": {
        "id": "a3XH3qw7Cjyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "qeDOnoB1ClnD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    check_dataset('dataset')\n",
        "    download_images('polar bear', 5, False)\n",
        "    download_images('brown bear', 5, False)"
      ],
      "metadata": {
        "id": "rjc4E0-YCmto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "d-Vk5Zn0Cnoc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}