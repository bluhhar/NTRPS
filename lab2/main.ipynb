{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURR_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка наличия репозиториев датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset():\n",
    "    dataset_directory = os.path.join(CURR_DIR, 'dataset')\n",
    "    if not os.path.exists(dataset_directory):\n",
    "        os.makedirs(dataset_directory)\n",
    "\n",
    "def check_repo_dataset(class_name):\n",
    "    class_folder = os.path.join(CURR_DIR + '\\dataset', class_name)\n",
    "    if not os.path.exists(class_folder):\n",
    "        os.makedirs(class_folder)\n",
    "        return class_folder\n",
    "    else:\n",
    "        return class_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсер ссылки на картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_url(url):\n",
    "    pattern = r'img_url=([^&]+)&text='\n",
    "    match = re.search(pattern, url)\n",
    "\n",
    "    if match:\n",
    "        img_url_encoded = match.group(1)\n",
    "        img_url_decoded = img_url_encoded.replace('%2F', '/').replace('%3A', ':')\n",
    "        return img_url_decoded\n",
    "    else:\n",
    "        print('Ссылка после img_url не найдена в URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисления необходимого количества страниц для скачивания (1 страница = 30 картинкам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pages(num_images):\n",
    "    return num_images // 30 + (num_images % 30 > 0) if num_images > 30 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение HTML тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_tags(mini_images):\n",
    "    if mini_images:\n",
    "        return 'img', 'serp-item__thumb', 'src'\n",
    "    else:\n",
    "        return 'a', 'serp-item__link', 'href'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закачка картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent':'Mozilla/5.0'}, stream=True)\n",
    "        if(response.status_code == 200):\n",
    "            with open(save_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    file.write(chunk)\n",
    "            return True\n",
    "        else:\n",
    "            print(f'Не удалось загрузить изображение: {url}')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'Ошибка при загрузке изображения: {url}')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(query, num_images, mini_images = False):\n",
    "    pages = calc_pages(num_images)\n",
    "    class_folder = check_repo_dataset(query)\n",
    "    \n",
    "    downloaded_count = 0\n",
    "\n",
    "    base_url = 'https:'\n",
    "\n",
    "    csv_file_path = class_folder + 'dataset.csv'\n",
    "\n",
    "    #а вот это чтобы без движков было, грузим странички\n",
    "    for page in range(0, pages):\n",
    "        search_url = f'https://yandex.ru/images/search?text={query}&p={page}'\n",
    "\n",
    "        with open(csv_file_path, 'w', newline='') as csv_file:\n",
    "            csv_writer = csv.writer(csv_file)\n",
    "            csv_writer.writerow(['date', 'file_name', 'url'])\n",
    "\n",
    "        #сделал с with для автоматического закрытия соединения\n",
    "        with requests.get(search_url, headers={'User-Agent':'Mozilla/5.0'}) as response:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            tag, tag_class, tag_source = get_html_tags(mini_images)\n",
    "\n",
    "            for a in soup.find_all(tag, class_=tag_class):\n",
    "                img_url = a[tag_source]\n",
    "                # получаем полный URL изображения\n",
    "                if mini_images and not img_url.startswith('http'):\n",
    "                    img_url = base_url + img_url\n",
    "                elif img_url.startswith('/images'):\n",
    "                    img_url = parser_url(img_url)\n",
    "\n",
    "                #csv_image_filename = image_filename\n",
    "                image_filename = f'{downloaded_count:04d}.jpg'\n",
    "                image_path = os.path.join(class_folder, image_filename)\n",
    "                if(download_image(img_url, image_path)):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"Загружено изображений для {query}: {downloaded_count}/{num_images}\")\n",
    "\n",
    "                    with open(csv_file_path, 'a', newline='') as csv_file:\n",
    "                        csv_writer = csv.writer(csv_file)\n",
    "                        csv_writer.writerow([datetime.now().strftime('%Y-%m-%d'), image_filename, img_url])\n",
    "\n",
    "                if(downloaded_count >= num_images):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    check_dataset()\n",
    "    download_images('polar bear', 5, True)\n",
    "    download_images('brown bear', 5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загружено изображений для polar bear: 1/50\n",
      "Загружено изображений для polar bear: 2/50\n",
      "Загружено изображений для polar bear: 3/50\n",
      "Загружено изображений для polar bear: 4/50\n",
      "Загружено изображений для polar bear: 5/50\n",
      "Загружено изображений для polar bear: 6/50\n",
      "Загружено изображений для polar bear: 7/50\n",
      "Загружено изображений для polar bear: 8/50\n",
      "Загружено изображений для polar bear: 9/50\n",
      "Загружено изображений для polar bear: 10/50\n",
      "Загружено изображений для polar bear: 11/50\n",
      "Загружено изображений для polar bear: 12/50\n",
      "Загружено изображений для polar bear: 13/50\n",
      "Загружено изображений для polar bear: 14/50\n",
      "Загружено изображений для polar bear: 15/50\n",
      "Загружено изображений для polar bear: 16/50\n",
      "Загружено изображений для polar bear: 17/50\n",
      "Загружено изображений для polar bear: 18/50\n",
      "Загружено изображений для polar bear: 19/50\n",
      "Загружено изображений для polar bear: 20/50\n",
      "Загружено изображений для polar bear: 21/50\n",
      "Загружено изображений для polar bear: 22/50\n",
      "Загружено изображений для polar bear: 23/50\n",
      "Загружено изображений для polar bear: 24/50\n",
      "Загружено изображений для polar bear: 25/50\n",
      "Загружено изображений для polar bear: 26/50\n",
      "Загружено изображений для polar bear: 27/50\n",
      "Загружено изображений для polar bear: 28/50\n",
      "Загружено изображений для polar bear: 29/50\n",
      "Загружено изображений для polar bear: 30/50\n",
      "Загружено изображений для polar bear: 31/50\n",
      "Загружено изображений для polar bear: 32/50\n",
      "Загружено изображений для polar bear: 33/50\n",
      "Загружено изображений для polar bear: 34/50\n",
      "Загружено изображений для polar bear: 35/50\n",
      "Загружено изображений для polar bear: 36/50\n",
      "Загружено изображений для polar bear: 37/50\n",
      "Загружено изображений для polar bear: 38/50\n",
      "Загружено изображений для polar bear: 39/50\n",
      "Загружено изображений для polar bear: 40/50\n",
      "Загружено изображений для polar bear: 41/50\n",
      "Загружено изображений для polar bear: 42/50\n",
      "Загружено изображений для polar bear: 43/50\n",
      "Загружено изображений для polar bear: 44/50\n",
      "Загружено изображений для polar bear: 45/50\n",
      "Загружено изображений для polar bear: 46/50\n",
      "Загружено изображений для polar bear: 47/50\n",
      "Загружено изображений для polar bear: 48/50\n",
      "Загружено изображений для polar bear: 49/50\n",
      "Загружено изображений для polar bear: 50/50\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
