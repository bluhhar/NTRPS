{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка наличия репозиториев датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_dataset():\n",
    "    dataset_directory = os.path.join(CURR_DIR, 'dataset')\n",
    "    if not os.path.exists(dataset_directory):\n",
    "        os.makedirs(dataset_directory)\n",
    "\n",
    "def check_repo_dataset(class_name):\n",
    "    class_folder = os.path.join(CURR_DIR + '\\dataset', class_name)\n",
    "    if not os.path.exists(class_folder):\n",
    "        os.makedirs(class_folder)\n",
    "        return class_folder\n",
    "    else:\n",
    "        return class_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсер ссылки на картинку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser_url(url):\n",
    "    pattern = r'img_url=([^&]+)&text='\n",
    "    match = re.search(pattern, url)\n",
    "\n",
    "    if match:\n",
    "        img_url_encoded = match.group(1)\n",
    "        img_url_decoded = img_url_encoded.replace('%2F', '/').replace('%3A', ':')\n",
    "        return img_url_decoded\n",
    "    else:\n",
    "        print('Ссылка после img_url не найдена в URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычисления необходимого количества страниц для скачивания (1 страница = 30 картинкам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_pages(num_images):\n",
    "    return num_images // 30 + (num_images % 30 > 0) if num_images > 30 else 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получение HTML тегов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html_tags(mini_images):\n",
    "    if mini_images:\n",
    "        return 'img', 'serp-item__thumb', 'src'\n",
    "    else:\n",
    "        return 'a', 'serp-item__link', 'href'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закачка картинок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url, save_path):\n",
    "    try:\n",
    "        response = requests.get(url, headers={'User-Agent':'Mozilla/5.0'}, stream=True)\n",
    "        if(response.status_code == 200):\n",
    "            with open(save_path, 'wb') as file:\n",
    "                for chunk in response.iter_content(1024):\n",
    "                    file.write(chunk)\n",
    "            return True\n",
    "        else:\n",
    "            print(f'Не удалось загрузить изображение: {url}')\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f'Ошибка при загрузке изображения: {url}')\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(query, num_images, mini_images = False):\n",
    "    pages = calc_pages(num_images)\n",
    "    class_folder = check_repo_dataset(query)\n",
    "\n",
    "    downloaded_count = 0\n",
    "\n",
    "    base_url = 'https:'\n",
    "\n",
    "    #а вот это чтобы без движков было, грузим странички\n",
    "    for page in range(0, pages):\n",
    "        search_url = f'https://yandex.ru/images/search?text={query}&p={page}'\n",
    "        \n",
    "        #сделал с with для автоматического закрытия соединения\n",
    "        with requests.get(search_url, headers={'User-Agent':'Mozilla/5.0'}) as response:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            tag, tag_class, tag_source = get_html_tags(mini_images)\n",
    "\n",
    "            for a in soup.find_all(tag, class_=tag_class):\n",
    "                img_url = a[tag_source]\n",
    "                # получаем полный URL изображения\n",
    "                if mini_images and not img_url.startswith('http'):\n",
    "                    img_url = base_url + img_url\n",
    "                elif img_url.startswith('/images'):\n",
    "                    img_url = parser_url(img_url)\n",
    "\n",
    "                image_filename = f'{downloaded_count:04d}.jpg'\n",
    "                image_path = os.path.join(class_folder, image_filename)\n",
    "                if(download_image(img_url, image_path)):\n",
    "                    downloaded_count += 1\n",
    "                    print(f\"Загружено изображений для {query}: {downloaded_count}/{num_images}\")\n",
    "\n",
    "                if(downloaded_count >= num_images):\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    check_dataset()\n",
    "    download_images('polar bear', 50, True)\n",
    "    download_images('brown bear', 50, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
